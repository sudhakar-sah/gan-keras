{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set GPU:\n",
      "This session will use GPU 0 and  0.5of the available GPU\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "# from keras.models import *\n",
    "# from keras.layers import *\n",
    "from keras.layers.core import *\n",
    "from keras.layers.pooling import *\n",
    "\n",
    "from keras.layers.convolutional import *\n",
    "from keras.regularizers import *\n",
    "from keras.layers.normalization import *\n",
    "from keras.optimizers import *\n",
    "from keras.constraints import *\n",
    "from keras.layers.noise import *\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, Dropout, Flatten, BatchNormalization, Reshape, GaussianNoise, UpSampling2D, Conv2DTranspose\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import Activation, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from termcolor import colored \n",
    "import random \n",
    "\n",
    "from tqdm import tqdm \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython import display\n",
    "gln = 'glorot_normal'\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "import warnings \n",
    "\n",
    "img_height = 28\n",
    "img_width = 28 \n",
    "\n",
    "def supress_warnings():\n",
    "\twarnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def gpu_conf(gpu_id =0, \n",
    "\t\t\t load = 0.8):\n",
    "\tos.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "\tos.environ[\"CUDA_VISIBLE_DEVICES\"]=str(gpu_id)\n",
    "\n",
    "\tif K._backend=='tensorflow':\n",
    "\t    print ('Set GPU:')\n",
    "\t    import tensorflow as tf\n",
    "\t    gpu_load = load\n",
    "\n",
    "\t    tf.device('/gpu:' + str(gpu_id))\n",
    "\t    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_load)\n",
    "\t    sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\t    #sess=tf.Session()\n",
    "\t    K.set_session(sess)\n",
    "\n",
    "\t    print (\"This session will use GPU \" + str(gpu_id) + \" and  \" + str(load) + \"of the available GPU\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "gpu_conf(gpu_id=0, \n",
    "    load = 0.5)\n",
    "\n",
    "# descriminator model definition \n",
    "\n",
    "def descriminator(img_dimensions):\n",
    "\n",
    "\tdropout_rate = 0.4 \n",
    "\t# height = img_dimensions[0]\n",
    "\t# width = img_dimensions[1]\n",
    "\t# channels = img_dimensions[2]\n",
    "\n",
    "\t# input_shape = (height, width, channels)\n",
    "\n",
    "\tmodel_input = Input(shape = img_dimensions.shape)\n",
    "\n",
    "\n",
    "\t#x = Conv2D(filters = 64, kernel_size = 5, strids =, padding = , data_format = , activation=, use_bias=, kernel_initializer =, bias_initialize =)\n",
    "\n",
    "\tx = Conv2D(filters = 64, kernel_size = 5, strides = 2, padding = 'same')(model_input)\n",
    "\tx = LeakyReLU(alpha=0.2)(x)\n",
    "\tx = Dropout(dropout_rate)(x)\n",
    "\n",
    "\tx = Conv2D(filters = 128, kernel_size = 5, strides = 2, padding = 'same')(x)\n",
    "\tx = LeakyReLU(alpha=0.2)(x)\n",
    "\tx = Dropout(dropout_rate)(x)\n",
    "\n",
    "\tx = Conv2D(filters = 256, kernel_size = 5, strides = 2, padding = 'same')(x)\n",
    "\tx = LeakyReLU(alpha=0.2)(x)\n",
    "\tx = Dropout(dropout_rate)(x)\n",
    "\n",
    "\tx = Conv2D(filters = 512, kernel_size = 5, strides = 2, padding = 'same')(x)\n",
    "\tx = LeakyReLU(alpha=0.2)(x)\n",
    "\tx = Dropout(dropout_rate)(x)\n",
    "\n",
    "\tx = Flatten()(x)\n",
    "\tx = Dense(2)(x)\n",
    "\tx = Activation('sigmoid')(x)\n",
    "\n",
    "\tmodel = Model(inputs=model_input, outputs=x)\n",
    "\n",
    "\treturn model\n",
    "\n",
    "\n",
    "# generator model definition \n",
    "\n",
    "def generator(g_input):\n",
    "\n",
    "\n",
    "\tdim = 7 \n",
    "\tdepth = 64 + 64 + 64 + 64\n",
    "\tinput_shape = (100,1)\n",
    "\tdropout_rate = 0.4\n",
    "\n",
    "\t\n",
    "\n",
    "\t# x = GaussianNoise(stddev = 1.0)(g_input)\n",
    "\tx = Dense(7*7*256, input_shape = input_shape, init=gln)(g_input)\n",
    "\tx = BatchNormalization(momentum = 0.9)(x)\n",
    "\tx = Activation('relu')(x)\n",
    "\tx = Reshape((dim, dim, depth))(x)\n",
    "\tx = Dropout(dropout_rate)(x)\n",
    "\n",
    "\tx = UpSampling2D()(x)\n",
    "\tx = Conv2DTranspose(filters=128, kernel_size=5, padding='same')(x)\n",
    "\tx = BatchNormalization(momentum = 0.9)(x)\n",
    "\tx = Activation('relu')(x)\n",
    "\n",
    "\tx = UpSampling2D()(x)\n",
    "\tx = Conv2DTranspose(filters=64, kernel_size=5, padding='same')(x)\n",
    "\tx = BatchNormalization(momentum = 0.9)(x)\n",
    "\tx = Activation('relu')(x)\n",
    "\n",
    "\tx = Conv2DTranspose(filters=32, kernel_size=5, padding='same')(x)\n",
    "\tx = BatchNormalization(momentum = 0.9)(x)\n",
    "\tx = Activation('relu')(x)\n",
    "\t\n",
    "\tx = Conv2DTranspose(filters=3, kernel_size=5, padding='same')(x)\n",
    "\tx = Activation('sigmoid')(x)\n",
    "\n",
    "\tmodel = Model(inputs = g_input, outputs = x)\n",
    "\n",
    "\treturn model\n",
    "\n",
    "\n",
    "# definition of gan model \n",
    "\n",
    "def stacked_gan(desc_model, gen_model):\n",
    "\t# freeze weights for the discriminator model for stacked training \n",
    "\tmake_trainable(desc_model, False)\n",
    "\t\t\n",
    "\tgan_input = Input(shape=[100])\n",
    "\tH = gen_model(gan_input)\n",
    "\tgan_V = desc_model(H)\n",
    "\tGAN = Model(gan_input, gan_V)\n",
    "\n",
    "\treturn GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 28, 28, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 14, 14, 64)        4864      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 7, 7, 128)         204928    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 4, 4, 256)         819456    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 2, 2, 512)         3277312   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 4098      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 4,310,658\n",
      "Trainable params: 4,310,658\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# initialize the descriminator model \n",
    "img_dim = np.zeros((img_height,img_width,3))\n",
    "desc_model = descriminator(img_dim)\n",
    "desc_opt = Adam(lr=1e-3)\n",
    "desc_model.compile(loss = 'categorical_crossentropy', optimizer=desc_opt)\n",
    "desc_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sudhakar/dl/local/lib/python2.7/site-packages/ipykernel_launcher.py:131: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12544, kernel_initializer=\"glorot_normal\", input_shape=(100, 1))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 12544)             1266944   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 12544)             50176     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 14, 14, 128)       819328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr (None, 28, 28, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTr (None, 28, 28, 32)        51232     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTr (None, 28, 28, 3)         2403      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 28, 28, 3)         0         \n",
      "=================================================================\n",
      "Total params: 2,395,843\n",
      "Trainable params: 2,370,307\n",
      "Non-trainable params: 25,536\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# initialze the generator model \n",
    "g_input = Input(shape=[100])\n",
    "gen_model = generator(g_input)\n",
    "gen_opt = Adam(lr=1e-4)\n",
    "gen_model.compile(loss='binary_crossentropy', optimizer=gen_opt)\n",
    "gen_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 127/13234 [00:00<00:10, 1266.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mprocessing face data ...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13234/13234 [00:08<00:00, 1546.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mdone.\u001b[0m\n",
      "\u001b[36mX_train shape: 13234\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "def face_data():\n",
    "\t\n",
    "\t# create mnist dataset \n",
    "\n",
    "\tpath = \"/nas/sudhakar/eyeem/mobile/ssd/org/ssd_eyeem/gan/images/faces/faces.npy\"\n",
    "\tfaces = np.load(path).item()\n",
    "\n",
    "\tX_train = np.zeros((len(faces), 64, 64, 3))\n",
    "\n",
    "\tcnt = 0\n",
    "\n",
    "\tprint(colored(\"processing face data ...\", \"cyan\"))\n",
    "\tfor key in tqdm(faces):\n",
    "\t\timg = cv2.imread(key)\n",
    "\t\t# print (key)\n",
    "\t\tX_train[cnt,:,:,:] = img\n",
    "\t\tcnt +=1 \n",
    "\n",
    "\t# if(cnt >0):\n",
    "\t# \tbreak\n",
    "\t# img.shape\n",
    "\n",
    "\tX_train /= 255. \n",
    "\n",
    "\tprint (colored(\"done.\", \"green\"))\n",
    "\tprint (colored('X_train shape: ' + str(X_train.shape[0]), \"cyan\"))\n",
    "\n",
    "\treturn X_train\n",
    "\t\n",
    "X_train = face_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "losses = {\"d\": [], \"g\": []}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
